{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART OF SPEECH TAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"NLP is fun. I'm studying NLP. Help me on this.\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP is fun.\n",
      "I'm studying NLP.\n",
      "Help me on this.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP\t0\tNLP\n",
      "is\t4\tbe\n",
      "fun\t7\tfun\n",
      ".\t10\t.\n",
      "I\t12\tI\n",
      "'m\t13\tbe\n",
      "studying\t16\tstudy\n",
      "NLP\t25\tNLP\n",
      ".\t28\t.\n",
      "Help\t30\thelp\n",
      "me\t35\tI\n",
      "on\t38\ton\n",
      "this\t41\tthis\n",
      ".\t45\t.\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text}\\t{token.idx}\\t{token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP\t\t0\t\tNLP\t\tPROPN\t\tproper noun\n",
      "is\t\t4\t\tbe\t\tAUX\t\tauxiliary\n",
      "fun\t\t7\t\tfun\t\tADJ\t\tadjective\n",
      ".\t\t10\t\t.\t\tPUNCT\t\tpunctuation\n",
      "I\t\t12\t\tI\t\tPRON\t\tpronoun\n",
      "'m\t\t13\t\tbe\t\tAUX\t\tauxiliary\n",
      "studying\t\t16\t\tstudy\t\tVERB\t\tverb\n",
      "NLP\t\t25\t\tNLP\t\tPROPN\t\tproper noun\n",
      ".\t\t28\t\t.\t\tPUNCT\t\tpunctuation\n",
      "Help\t\t30\t\thelp\t\tVERB\t\tverb\n",
      "me\t\t35\t\tI\t\tPRON\t\tpronoun\n",
      "on\t\t38\t\ton\t\tADP\t\tadposition\n",
      "this\t\t41\t\tthis\t\tPRON\t\tpronoun\n",
      ".\t\t45\t\t.\t\tPUNCT\t\tpunctuation\n"
     ]
    }
   ],
   "source": [
    "# POS tagging\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text}\\t\\t{token.idx}\\t\\t{token.lemma_}\\t\\t{token.pos_}\\t\\t{spacy.explain(token.pos_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'ADD', 'AFX', 'CC', 'CD', 'DT', 'EX', 'FW', 'HYPH', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NFP', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', 'XX', '_SP', '``')\n"
     ]
    }
   ],
   "source": [
    "print(nlp.get_pipe(\"tagger\").labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'left round bracket'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"-LRB-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP\t\t0\t\tNLP\t\tPROPN\t\tproper noun\t\tNumber=Sing\n",
      "is\t\t4\t\tbe\t\tAUX\t\tauxiliary\t\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "fun\t\t7\t\tfun\t\tADJ\t\tadjective\t\tDegree=Pos\n",
      ".\t\t10\t\t.\t\tPUNCT\t\tpunctuation\t\tPunctType=Peri\n",
      "I\t\t12\t\tI\t\tPRON\t\tpronoun\t\tCase=Nom|Number=Sing|Person=1|PronType=Prs\n",
      "'m\t\t13\t\tbe\t\tAUX\t\tauxiliary\t\tMood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin\n",
      "studying\t\t16\t\tstudy\t\tVERB\t\tverb\t\tAspect=Prog|Tense=Pres|VerbForm=Part\n",
      "NLP\t\t25\t\tNLP\t\tPROPN\t\tproper noun\t\tNumber=Sing\n",
      ".\t\t28\t\t.\t\tPUNCT\t\tpunctuation\t\tPunctType=Peri\n",
      "Help\t\t30\t\thelp\t\tVERB\t\tverb\t\tVerbForm=Inf\n",
      "me\t\t35\t\tI\t\tPRON\t\tpronoun\t\tCase=Acc|Number=Sing|Person=1|PronType=Prs\n",
      "on\t\t38\t\ton\t\tADP\t\tadposition\t\t\n",
      "this\t\t41\t\tthis\t\tPRON\t\tpronoun\t\tNumber=Sing|PronType=Dem\n",
      ".\t\t45\t\t.\t\tPUNCT\t\tpunctuation\t\tPunctType=Peri\n"
     ]
    }
   ],
   "source": [
    "#morphology analyze\n",
    "for token in doc:\n",
    "    print(f\"{token.text}\\t\\t{token.idx}\\t\\t{token.lemma_}\\t\\t{token.pos_}\\t\\t{spacy.explain(token.pos_)}\\t\\t{token.morph}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAMED ENTITY RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP\tORG\n",
      "NLP\tORG\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"NLP is fun. I'm studying NLP. Help me on this.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text}\\t{ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NLP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is fun. I'm studying \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NLP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". Help me on this.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True, options={'distance': 150})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example - check if the given text parts are in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired output : \n",
    "\n",
    "# text = \"I will visit you on 2024 June at your office.\"\n",
    "# output = date and place are in the right format. / date might be in the wrong format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-June\tDATE\n",
      "Teknopark\tGPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"I will visit you on 2024-June at Teknopark.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text}\\t{ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\t\t0\t\tPRON\n",
      "will\t\t2\t\tAUX\n",
      "visit\t\t7\t\tVERB\n",
      "you\t\t13\t\tPRON\n",
      "on\t\t17\t\tADP\n",
      "2024\t\t20\t\tNUM\n",
      "-\t\t24\t\tSYM\n",
      "June\t\t25\t\tPROPN\n",
      "at\t\t30\t\tADP\n",
      "Teknopark\t\t33\t\tPROPN\n",
      ".\t\t42\t\tPUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text}\\t\\t{token.idx}\\t\\t{token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'will', 'visit', 'you', 'on', '2024-June', 'at', 'Teknopark.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste = text.split(\" \")\n",
    "liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "june 1974 19 06 2023 monday\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"June-1974 19.06.2023 monday\"\n",
    "remove_puncts = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "print(remove_puncts.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all possible outcome lchecker:  -->  mon is true for monday but mo is not.\n",
    "\n",
    "def all_days(word):\n",
    "    word = word.lower()\n",
    "    days = [\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\"]\n",
    "    \n",
    "    if word.isdigit() and 1 <= int(word) <= 31:\n",
    "        return True\n",
    "    \n",
    "    return any(day.startswith(word) for day in days)\n",
    "\n",
    "def all_months(word):\n",
    "    word = word.lower()\n",
    "    months = [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"]\n",
    "    return any(month.startswith(word) for month in months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'June 12, 2023' is in the right format.\n",
      "'Teknopark' is a valid place.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def check_date_format(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"DATE\":\n",
    "            remove_puncts = re.sub(r\"[^\\w\\s]\", \" \", ent.text)\n",
    "            remove_puncts = remove_puncts.lower().split()\n",
    "\n",
    "            day_found = False\n",
    "            month_found = False\n",
    "            for token in remove_puncts:\n",
    "                if all_days(token):\n",
    "                    day_found = True\n",
    "                if all_months(token):\n",
    "                    month_found = True\n",
    "\n",
    "            if day_found and month_found:\n",
    "                return f\"'{ent.text}' is in the right format.\"\n",
    "            else:\n",
    "                return f\"'{ent.text}' might be in the wrong format.\"\n",
    "    return \"No date found.\"\n",
    "\n",
    "def check_place(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"GPE\":\n",
    "            if ent.text.lower() in [\"teknopark\", \"mugla\", \"msku\"]:\n",
    "                return f\"'{ent.text}' is a valid place.\"\n",
    "            else:\n",
    "                return f\"'{ent.text}' might not be a valid place.\"\n",
    "    return \"No place found.\"\n",
    "\n",
    "text = \"I will visit Mugla on June 12, 2023, and then travel to Teknopark.\"\n",
    "\n",
    "print(check_date_format(text))\n",
    "print(check_place(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
